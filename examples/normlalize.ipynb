{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from data.transform import Normalize\n",
    "\n",
    "# Print mean and std.\n",
    "\n",
    "def print_ms(x):\n",
    "    if not isinstance(x, dict):\n",
    "        x = {'x': x}\n",
    "    for key, val in x.items():\n",
    "        print(f'{key}: mean={val.mean()}, std={val.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (site: 3, time: 500)\n",
      "Coordinates:\n",
      "  * time     (time) int64 0 1 2 3 4 5 6 7 8 ... 492 493 494 495 496 497 498 499\n",
      "  * site     (site) <U2 'S0' 'S1' 'S2'\n",
      "Data variables:\n",
      "    x0       (time, site) float32 1.09 10.31 5.584 ... -11.04 -23.95 -2.894\n",
      "    x1       (time, site) float32 19.0 0.7931 -6.42 ... -14.48 1.759 -5.892\n",
      "    x2       (time, site) float32 1.05 8.91 -15.48 -4.477 ... -1.247 16.42 -30.0\n"
     ]
    }
   ],
   "source": [
    "# Craete dummy xarray data.\n",
    "\n",
    "seq_len = 500\n",
    "num_sites = 3\n",
    "ds = xr.Dataset()\n",
    "for x in range(3):\n",
    "    # Random data with different mean (=x)\n",
    "    ds[f'x{x}'] = xr.DataArray(np.random.normal(loc=x, scale=10., size=(seq_len, num_sites)).astype('float32'), dims=['time', 'site'], coords={'time': range(seq_len), 'site': [f'S{s}' for s in range(num_sites)]})\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set.\n",
    "\n",
    "train_ds = ds.sel(site='S0').isel(time=range(250))\n",
    "valid_ds = ds.sel(site='S0').isel(time=range(250, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize(dtype=float32)\n",
      "----------------------------------------\n",
      " * x0: 0.373 (9.863 std)\n",
      " * x1: 0.866 (9.996 std)\n",
      " * x2: 1.483 (9.983 std)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a normalizer using training data.\n",
    "\n",
    "norm = Normalize()\n",
    "norm.register_dict({\n",
    "    'x0': train_ds.x0.values,\n",
    "    'x1': train_ds.x1.values,\n",
    "    'x2': train_ds.x2.values,\n",
    "})\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple pytorch dataset.\n",
    "\n",
    "class SiteData(Dataset):\n",
    "    def __init__(self, ds, dtype=np.float32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ds = ds\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds.time)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        d = self.ds.isel(time=ind)\n",
    "        return {\n",
    "            'x0': d['x0'].values.astype(self.dtype),\n",
    "            'x1': d['x1'].values.astype(self.dtype),\n",
    "            'x2': d['x2'].values.astype(self.dtype),\n",
    "        }\n",
    "\n",
    "data = SiteData(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x0': array(1.0901693, dtype=float32), 'x1': array(19.000296, dtype=float32), 'x2': array(1.0497253, dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# Load one sample.\n",
    "\n",
    "d = data[0]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07275067  1.814245   -0.04344677]\n"
     ]
    }
   ],
   "source": [
    "# Normalize sample.\n",
    "\n",
    "d_norm = norm.normalize_dict(d, return_stack=True)\n",
    "print(d_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buid a pytorch dataloader.\n",
    "\n",
    "dl = DataLoader(data, batch_size=16)\n",
    "\n",
    "# Get first batch.\n",
    "\n",
    "batch = next(iter(dl))\n",
    "\n",
    "# Access data;\n",
    "\n",
    "x0 = batch['x0']\n",
    "x1 = batch['x1']\n",
    "x2 = batch['x2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validity check.\n",
    "\n",
    "torch.isclose(x2, norm.unnormalize('x2', norm.normalize('x2', x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: mean=0.10862809419631958, std=1.0552358627319336\n"
     ]
    }
   ],
   "source": [
    "# Normalize single variable.\n",
    "\n",
    "print_ms(norm.normalize('x2', x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: mean=0.1362379938364029, std=1.0460177659988403\n",
      "x1: mean=0.01050223782658577, std=1.21055006980896\n",
      "x2: mean=0.10862809419631958, std=1.0552358627319336\n"
     ]
    }
   ],
   "source": [
    "# Normalize entire batch.\n",
    "\n",
    "print_ms(norm.normalize_dict(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': tensor([ 0.0728, -2.0438, -1.1695,  0.7588,  0.0594, -0.6604,  0.2844,  0.0445,\n",
       "          1.9129, -0.8462,  0.2230,  1.7483, -0.3065, -0.1191,  1.0643,  1.1569]),\n",
       " 'x1': tensor([ 1.8142, -0.5482, -1.2990,  0.0083,  0.2917,  1.1285,  0.5940, -2.5928,\n",
       "          1.0833,  0.8032,  1.7588,  0.1065, -1.3017,  0.1294, -0.8937, -0.9145])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize a subset of variables in batch.\n",
    "\n",
    "norm.normalize_dict(batch, variables=['x0', 'x1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize a subset of variables in batch and stack along last dimension.\n",
    "\n",
    "x = norm.normalize_dict(batch, variables=['x0', 'x1'], return_stack=True)\n",
    "\n",
    "# The first dimension is the batch size, the second the two variables that we selected, x0 and x1.\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
